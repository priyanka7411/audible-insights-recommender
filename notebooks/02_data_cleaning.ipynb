{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "779e519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ccb9c7",
   "metadata": {},
   "source": [
    "## 1. Load Merged Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ade8c641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (7576, 11)\n",
      "Columns: ['Book_Name', 'Author', 'Rating', 'Number_of_Reviews', 'Price', 'Description', 'Listening_Time', 'Ranks_and_Genre', 'Has_Basic_Data', 'Has_Advanced_Data', 'Data_Source']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the merged dataset from previous step\n",
    "df = pd.read_csv('/Users/priyankamalavade/Desktop/Audible_Insights_Project/data/merged_audible_dataset.csv')\n",
    "\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "985be159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset Overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7576 entries, 0 to 7575\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Book_Name          7576 non-null   object \n",
      " 1   Author             7576 non-null   object \n",
      " 2   Rating             7576 non-null   float64\n",
      " 3   Number_of_Reviews  6832 non-null   float64\n",
      " 4   Price              7574 non-null   float64\n",
      " 5   Description        5001 non-null   object \n",
      " 6   Listening_Time     5008 non-null   object \n",
      " 7   Ranks_and_Genre    5008 non-null   object \n",
      " 8   Has_Basic_Data     7576 non-null   bool   \n",
      " 9   Has_Advanced_Data  7576 non-null   bool   \n",
      " 10  Data_Source        7576 non-null   object \n",
      "dtypes: bool(2), float64(3), object(6)\n",
      "memory usage: 547.6+ KB\n",
      "None\n",
      "\n",
      " Missing Values Summary:\n",
      "Number_of_Reviews     744\n",
      "Price                   2\n",
      "Description          2575\n",
      "Listening_Time       2568\n",
      "Ranks_and_Genre      2568\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display basic info\n",
    "print(\" Dataset Overview:\")\n",
    "print(df.info())\n",
    "print()\n",
    "\n",
    "# Check missing values\n",
    "print(\" Missing Values Summary:\")\n",
    "missing_summary = df.isnull().sum()\n",
    "print(missing_summary[missing_summary > 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad7f2ed",
   "metadata": {},
   "source": [
    "## 2. Clean Basic Information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d63cea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Clean book names - remove extra whitespace and standardize\n",
    "df_clean['Book_Name'] = df_clean['Book_Name'].str.strip()\n",
    "df_clean['Book_Name'] = df_clean['Book_Name'].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# Clean author names - remove extra whitespace and standardize\n",
    "df_clean['Author'] = df_clean['Author'].str.strip()\n",
    "df_clean['Author'] = df_clean['Author'].str.replace(r'\\s+', ' ', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd3e4b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any books without names or authors\n",
    "initial_count = len(df_clean)\n",
    "df_clean = df_clean.dropna(subset=['Book_Name', 'Author'])\n",
    "df_clean = df_clean[df_clean['Book_Name'].str.len() > 0]\n",
    "df_clean = df_clean[df_clean['Author'].str.len() > 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d06d769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Removed 0 books with missing names/authors\n",
      " Remaining books: 7,576\n"
     ]
    }
   ],
   "source": [
    "print(f\" Removed {initial_count - len(df_clean)} books with missing names/authors\")\n",
    "print(f\" Remaining books: {len(df_clean):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d7af62",
   "metadata": {},
   "source": [
    "## 3. Clean Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e571bc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cleaning Ratings:\n",
      "Rating range before: -1.00 to 5.00\n",
      "Missing ratings: 0\n"
     ]
    }
   ],
   "source": [
    "# Clean Rating column\n",
    "print(\" Cleaning Ratings:\")\n",
    "print(f\"Rating range before: {df_clean['Rating'].min():.2f} to {df_clean['Rating'].max():.2f}\")\n",
    "print(f\"Missing ratings: {df_clean['Rating'].isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14abcc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings should be between 1.0 and 5.0\n",
    "df_clean['Rating'] = pd.to_numeric(df_clean['Rating'], errors='coerce')\n",
    "df_clean.loc[df_clean['Rating'] < 1.0, 'Rating'] = np.nan\n",
    "df_clean.loc[df_clean['Rating'] > 5.0, 'Rating'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1868ecd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Filled missing ratings with median: 4.50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fill missing ratings with median rating\n",
    "median_rating = df_clean['Rating'].median()\n",
    "df_clean['Rating'].fillna(median_rating, inplace=True)\n",
    "print(f\" Filled missing ratings with median: {median_rating:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56eb6c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cleaning Number of Reviews:\n",
      "Review count range before: 1 to 70122\n",
      "Missing review counts: 744\n"
     ]
    }
   ],
   "source": [
    "# Clean Number of Reviews\n",
    "print(\" Cleaning Number of Reviews:\")\n",
    "print(f\"Review count range before: {df_clean['Number_of_Reviews'].min():.0f} to {df_clean['Number_of_Reviews'].max():.0f}\")\n",
    "print(f\"Missing review counts: {df_clean['Number_of_Reviews'].isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "264bf802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numeric and handle negative values\n",
    "df_clean['Number_of_Reviews'] = pd.to_numeric(df_clean['Number_of_Reviews'], errors='coerce')\n",
    "df_clean.loc[df_clean['Number_of_Reviews'] < 0, 'Number_of_Reviews'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b98a06e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Filled missing review counts with 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fill missing review counts with 0 (assuming no reviews means 0 reviews)\n",
    "df_clean['Number_of_Reviews'].fillna(0, inplace=True)\n",
    "df_clean['Number_of_Reviews'] = df_clean['Number_of_Reviews'].astype(int)\n",
    "print(\" Filled missing review counts with 0\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db28c82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cleaning Prices:\n",
      "Price range before: $0.00 to $18290.00\n",
      "Missing prices: 2\n"
     ]
    }
   ],
   "source": [
    "# Clean Price column\n",
    "print(\" Cleaning Prices:\")\n",
    "print(f\"Price range before: ${df_clean['Price'].min():.2f} to ${df_clean['Price'].max():.2f}\")\n",
    "print(f\"Missing prices: {df_clean['Price'].isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07e66820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numeric and handle outliers\n",
    "df_clean['Price'] = pd.to_numeric(df_clean['Price'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c72f7875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books with price > $1000: 1540\n"
     ]
    }
   ],
   "source": [
    "# Remove extreme outliers (prices > $1000 might be data entry errors)\n",
    "extreme_prices = df_clean['Price'] > 1000\n",
    "print(f\"Books with price > $1000: {extreme_prices.sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2af5765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap extreme prices at 99th percentile\n",
    "price_99th = df_clean['Price'].quantile(0.99)\n",
    "df_clean.loc[df_clean['Price'] > price_99th, 'Price'] = price_99th\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b4a0534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Filled missing prices with median: $680.00\n"
     ]
    }
   ],
   "source": [
    "# Fill missing prices with median\n",
    "median_price = df_clean['Price'].median()\n",
    "df_clean['Price'].fillna(median_price, inplace=True)\n",
    "print(f\" Filled missing prices with median: ${median_price:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44c5599",
   "metadata": {},
   "source": [
    "## 4. Clean Listening Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7906238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_listening_time(time_str):\n",
    "    \"\"\"Convert listening time string to minutes\"\"\"\n",
    "    if pd.isna(time_str) or time_str == '':\n",
    "        return np.nan\n",
    "    \n",
    "    time_str = str(time_str).lower()\n",
    "    total_minutes = 0\n",
    "    \n",
    "    # Extract hours\n",
    "    hour_match = re.search(r'(\\d+)\\s*hour', time_str)\n",
    "    if hour_match:\n",
    "        total_minutes += int(hour_match.group(1)) * 60\n",
    "    \n",
    "    # Extract minutes\n",
    "    minute_match = re.search(r'(\\d+)\\s*minute', time_str)\n",
    "    if minute_match:\n",
    "        total_minutes += int(minute_match.group(1))\n",
    "    \n",
    "    return total_minutes if total_minutes > 0 else np.nan\n",
    "\n",
    "# Apply the parsing function\n",
    "df_clean['Listening_Time_Minutes'] = df_clean['Listening_Time'].apply(parse_listening_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11916157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully parsed listening times: 2354\n",
      "Missing listening times: 5222\n"
     ]
    }
   ],
   "source": [
    "print(f\"Successfully parsed listening times: {df_clean['Listening_Time_Minutes'].notna().sum()}\")\n",
    "print(f\"Missing listening times: {df_clean['Listening_Time_Minutes'].isna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a6baf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing listening times with median\n",
    "median_time = df_clean['Listening_Time_Minutes'].median()\n",
    "df_clean['Listening_Time_Minutes'].fillna(median_time, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cd0172c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Filled missing listening times with median: 490 minutes\n"
     ]
    }
   ],
   "source": [
    "print(f\" Filled missing listening times with median: {median_time:.0f} minutes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4a633f",
   "metadata": {},
   "source": [
    "## 5. Clean Genre Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f63e2b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_genres(genre_str):\n",
    "    \"\"\"Extract clean genre list from ranks and genre string\"\"\"\n",
    "    if pd.isna(genre_str) or genre_str == '':\n",
    "        return []\n",
    "    \n",
    "    # Split by commas and clean each genre\n",
    "    genres = []\n",
    "    parts = str(genre_str).split(',')\n",
    "    \n",
    "    for part in parts:\n",
    "        # Remove rankings like \"#1 in\" or \"#2 in\"\n",
    "        cleaned = re.sub(r'#\\d+\\s+in\\s+', '', part.strip())\n",
    "        \n",
    "        # Remove parenthetical information like \"(See Top 100 in...)\"\n",
    "        cleaned = re.sub(r'\\([^)]*\\)', '', cleaned)\n",
    "        \n",
    "        # Clean whitespace\n",
    "        cleaned = cleaned.strip()\n",
    "        \n",
    "        # Only keep non-empty genres\n",
    "        if cleaned and len(cleaned) > 2:\n",
    "            genres.append(cleaned)\n",
    "    \n",
    "    return genres\n",
    "\n",
    "# Extract genres\n",
    "df_clean['Genres'] = df_clean['Ranks_and_Genre'].apply(extract_genres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea50c6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books with genre information: 2359\n"
     ]
    }
   ],
   "source": [
    "# Count how many books have genres\n",
    "books_with_genres = df_clean['Genres'].apply(len) > 0\n",
    "print(f\"Books with genre information: {books_with_genres.sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5f2dad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique genres found: 2648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get all unique genres\n",
    "all_genres = []\n",
    "for genre_list in df_clean['Genres']:\n",
    "    all_genres.extend(genre_list)\n",
    "\n",
    "unique_genres = list(set(all_genres))\n",
    "print(f\"Total unique genres found: {len(unique_genres)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bbfc9986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Top 20 Most Common Genres:\n",
      "  Audible Audiobooks & Originals: 602\n",
      "  Personal Success: 222\n",
      "  Classic Literature: 94\n",
      "  Leadership: 83\n",
      "  Literary Fiction: 75\n",
      "  Thriller & Mystery: 71\n",
      "  Historical Fiction: 65\n",
      "  Meditation: 56\n",
      "  Contemporary Romance: 53\n",
      "  Personal Finance: 50\n",
      "  Business Management: 50\n",
      "  Psychology: 49\n",
      "  Business Careers: 47\n",
      "  Body & Spirit: 47\n",
      "  5 star: 45\n",
      "  Entrepreneurship: 43\n",
      "  Spirituality: 43\n",
      "  Business Motivation & Self-Improvement: 39\n",
      "  Analysis & Strategy: 37\n",
      "  Forecasting & Strategic Planning: 36\n"
     ]
    }
   ],
   "source": [
    "# Display most common genres\n",
    "from collections import Counter\n",
    "genre_counts = Counter(all_genres)\n",
    "print(\" Top 20 Most Common Genres:\")\n",
    "for genre, count in genre_counts.most_common(20):\n",
    "    print(f\"  {genre}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c934696b",
   "metadata": {},
   "source": [
    "## 6. Clean Description Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f515c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_description(desc):\n",
    "    \"\"\"Clean and standardize book descriptions\"\"\"\n",
    "    if pd.isna(desc) or desc == '':\n",
    "        return ''\n",
    "    \n",
    "    desc = str(desc)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    desc = re.sub(r'\\s+', ' ', desc)\n",
    "    \n",
    "    # Remove leading/trailing whitespace\n",
    "    desc = desc.strip()\n",
    "    \n",
    "    # Remove any HTML tags if present\n",
    "    desc = re.sub(r'<[^>]+>', '', desc)\n",
    "    \n",
    "    return desc\n",
    "\n",
    "# Clean descriptions\n",
    "df_clean['Description_Clean'] = df_clean['Description'].apply(clean_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "518e48e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate description lengths\n",
    "df_clean['Description_Length'] = df_clean['Description_Clean'].str.len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60621f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books with descriptions: 4999\n",
      "Average description length: 153 characters\n",
      "Median description length: 122 characters\n"
     ]
    }
   ],
   "source": [
    "descriptions_available = df_clean['Description_Length'] > 0\n",
    "print(f\"Books with descriptions: {descriptions_available.sum()}\")\n",
    "print(f\"Average description length: {df_clean['Description_Length'].mean():.0f} characters\")\n",
    "print(f\"Median description length: {df_clean['Description_Length'].median():.0f} characters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe8cd7",
   "metadata": {},
   "source": [
    "## 7. Create Derived Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "257c666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popularity score based on number of reviews\n",
    "df_clean['Popularity_Score'] = np.log1p(df_clean['Number_of_Reviews'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "516c7bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5.141664\n",
       "1    5.141664\n",
       "2    7.728856\n",
       "3    7.728856\n",
       "4    5.192957\n",
       "Name: Popularity_Score, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['Popularity_Score'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5e635ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating category\n",
    "def categorize_rating(rating):\n",
    "    if rating >= 4.5:\n",
    "        return 'Excellent'\n",
    "    elif rating >= 4.0:\n",
    "        return 'Very Good'\n",
    "    elif rating >= 3.5:\n",
    "        return 'Good'\n",
    "    elif rating >= 3.0:\n",
    "        return 'Average'\n",
    "    else:\n",
    "        return 'Below Average'\n",
    "\n",
    "df_clean['Rating_Category'] = df_clean['Rating'].apply(categorize_rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19c75a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price category\n",
    "price_quantiles = df_clean['Price'].quantile([0.25, 0.5, 0.75])\n",
    "def categorize_price(price):\n",
    "    if price <= price_quantiles[0.25]:\n",
    "        return 'Low'\n",
    "    elif price <= price_quantiles[0.5]:\n",
    "        return 'Medium-Low'\n",
    "    elif price <= price_quantiles[0.75]:\n",
    "        return 'Medium-High'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "df_clean['Price_Category'] = df_clean['Price'].apply(categorize_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39bad443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length category for listening time\n",
    "def categorize_length(minutes):\n",
    "    if minutes < 180:  # Less than 3 hours\n",
    "        return 'Short'\n",
    "    elif minutes < 480:  # Less than 8 hours\n",
    "        return 'Medium'\n",
    "    elif minutes < 900:  # Less than 15 hours\n",
    "        return 'Long'\n",
    "    else:\n",
    "        return 'Very Long'\n",
    "\n",
    "df_clean['Length_Category'] = df_clean['Listening_Time_Minutes'].apply(categorize_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b56facb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Created derived features:\n",
      "  - Popularity Score (log of reviews + 1)\n",
      "  - Rating Category: {'Excellent': 4878, 'Very Good': 2292, 'Good': 281, 'Average': 81, 'Below Average': 44}\n",
      "  - Price Category: {'Low': 2072, 'Medium-High': 2020, 'High': 1762, 'Medium-Low': 1722}\n",
      "  - Length Category: {'Long': 6025, 'Medium': 837, 'Very Long': 396, 'Short': 318}\n"
     ]
    }
   ],
   "source": [
    "print(\" Created derived features:\")\n",
    "print(f\"  - Popularity Score (log of reviews + 1)\")\n",
    "print(f\"  - Rating Category: {df_clean['Rating_Category'].value_counts().to_dict()}\")\n",
    "print(f\"  - Price Category: {df_clean['Price_Category'].value_counts().to_dict()}\")\n",
    "print(f\"  - Length Category: {df_clean['Length_Category'].value_counts().to_dict()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b67023c",
   "metadata": {},
   "source": [
    "## 8. Final Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "565bb20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Missing values after cleaning:\n",
      "Description        2575\n",
      "Listening_Time     2568\n",
      "Ranks_and_Genre    2568\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for any remaining issues\n",
    "print(\" Missing values after cleaning:\")\n",
    "missing_after = df_clean.isnull().sum()\n",
    "print(missing_after[missing_after > 0])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff285853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Duplicate book-author combinations: 1511\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "duplicates = df_clean.duplicated(subset=['Book_Name', 'Author']).sum()\n",
    "print(f\" Duplicate book-author combinations: {duplicates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72e0cf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing duplicates...\n",
      " Removed 1511 duplicates\n"
     ]
    }
   ],
   "source": [
    "if duplicates > 0:\n",
    "    print(\"Removing duplicates...\")\n",
    "    df_clean = df_clean.drop_duplicates(subset=['Book_Name', 'Author'], keep='first')\n",
    "    print(f\" Removed {duplicates} duplicates\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2eb7a209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Final dataset statistics:\n",
      "  - Total books: 6,065\n",
      "  - Books with descriptions: 4,005\n",
      "  - Books with genres: 2,047\n",
      "  - Average rating: 4.46\n",
      "  - Average reviews: 841\n",
      "  - Average price: $898.11\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\" Final dataset statistics:\")\n",
    "print(f\"  - Total books: {len(df_clean):,}\")\n",
    "print(f\"  - Books with descriptions: {(df_clean['Description_Length'] > 0).sum():,}\")\n",
    "print(f\"  - Books with genres: {(df_clean['Genres'].apply(len) > 0).sum():,}\")\n",
    "print(f\"  - Average rating: {df_clean['Rating'].mean():.2f}\")\n",
    "print(f\"  - Average reviews: {df_clean['Number_of_Reviews'].mean():.0f}\")\n",
    "print(f\"  - Average price: ${df_clean['Price'].mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad162297",
   "metadata": {},
   "source": [
    "## 9. Data Type Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7fbec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize data types to save memory\n",
    "df_clean = df_clean.astype({\n",
    "    'Number_of_Reviews': 'int32',\n",
    "    'Listening_Time_Minutes': 'float32',\n",
    "    'Description_Length': 'int32',\n",
    "    'Popularity_Score': 'float32',\n",
    "    'Rating': 'float32',\n",
    "    'Price': 'float32'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24c63ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns to category type\n",
    "categorical_columns = ['Rating_Category', 'Price_Category', 'Length_Category', 'Data_Source']\n",
    "for col in categorical_columns:\n",
    "    df_clean[col] = df_clean[col].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0356e185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Optimized data types for better memory usage\n",
      "\n",
      " Final dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6065 entries, 0 to 7572\n",
      "Data columns (total 19 columns):\n",
      " #   Column                  Non-Null Count  Dtype   \n",
      "---  ------                  --------------  -----   \n",
      " 0   Book_Name               6065 non-null   object  \n",
      " 1   Author                  6065 non-null   object  \n",
      " 2   Rating                  6065 non-null   float32 \n",
      " 3   Number_of_Reviews       6065 non-null   int32   \n",
      " 4   Price                   6065 non-null   float32 \n",
      " 5   Description             4007 non-null   object  \n",
      " 6   Listening_Time          4013 non-null   object  \n",
      " 7   Ranks_and_Genre         4013 non-null   object  \n",
      " 8   Has_Basic_Data          6065 non-null   bool    \n",
      " 9   Has_Advanced_Data       6065 non-null   bool    \n",
      " 10  Data_Source             6065 non-null   category\n",
      " 11  Listening_Time_Minutes  6065 non-null   float32 \n",
      " 12  Genres                  6065 non-null   object  \n",
      " 13  Description_Clean       6065 non-null   object  \n",
      " 14  Description_Length      6065 non-null   int32   \n",
      " 15  Popularity_Score        6065 non-null   float32 \n",
      " 16  Rating_Category         6065 non-null   category\n",
      " 17  Price_Category          6065 non-null   category\n",
      " 18  Length_Category         6065 non-null   category\n",
      "dtypes: bool(2), category(4), float32(4), int32(2), object(7)\n",
      "memory usage: 5.3 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\" Optimized data types for better memory usage\")\n",
    "print()\n",
    "print(\" Final dataset info:\")\n",
    "print(df_clean.info(memory_usage='deep'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf45c58",
   "metadata": {},
   "source": [
    "## 10. Save Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "828f868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare final columns for saving\n",
    "final_columns = [\n",
    "    'Book_Name', 'Author', 'Rating', 'Number_of_Reviews', 'Price',\n",
    "    'Description_Clean', 'Listening_Time_Minutes', 'Genres',\n",
    "    'Rating_Category', 'Price_Category', 'Length_Category',\n",
    "    'Popularity_Score', 'Description_Length', 'Data_Source'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab2fdba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_clean[final_columns].copy()\n",
    "\n",
    "# Save cleaned dataset\n",
    "output_filename = '/Users/priyankamalavade/Desktop/Audible_Insights_Project/data/cleaned_audible_dataset.csv'\n",
    "df_final.to_csv(output_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd24b313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cleaned dataset saved as: /Users/priyankamalavade/Desktop/Audible_Insights_Project/data/cleaned_audible_dataset.csv\n",
      " Final dataset shape: (6065, 14)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\" Cleaned dataset saved as: {output_filename}\")\n",
    "print(f\" Final dataset shape: {df_final.shape}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "540164a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sample of cleaned dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Number_of_Reviews</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Don't You Know Who I Am?\": How to Stay Sane i...</td>\n",
       "      <td>Ramani S. Durvasula PhD</td>\n",
       "      <td>4.8</td>\n",
       "      <td>170</td>\n",
       "      <td>836.0</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Girlboss</td>\n",
       "      <td>Sophia Amoruso</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2272</td>\n",
       "      <td>615.0</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#TheRealCinderella: #BestFriendsForever Series...</td>\n",
       "      <td>Yesenia Vargas</td>\n",
       "      <td>4.3</td>\n",
       "      <td>179</td>\n",
       "      <td>586.0</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10 Bedtime Stories For Little Kids</td>\n",
       "      <td>div.</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10 Essential Pieces of Literature</td>\n",
       "      <td>Khalil Gibran</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10 Essential Success Mantras from the Bhagavad...</td>\n",
       "      <td>Vimla Patil</td>\n",
       "      <td>4.2</td>\n",
       "      <td>45</td>\n",
       "      <td>233.0</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10 Judgements That Changed India</td>\n",
       "      <td>Zia Mody</td>\n",
       "      <td>4.4</td>\n",
       "      <td>221</td>\n",
       "      <td>502.0</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10 Masterpieces You Have to Read Before You Die 1</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>4.4</td>\n",
       "      <td>344</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10 Minutes 38 Seconds in This Strange World</td>\n",
       "      <td>Elif Shafak</td>\n",
       "      <td>4.5</td>\n",
       "      <td>520</td>\n",
       "      <td>752.0</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10 Skills for Effective Business Communication...</td>\n",
       "      <td>Jessica Higgins JD MBA BB</td>\n",
       "      <td>4.6</td>\n",
       "      <td>45</td>\n",
       "      <td>501.0</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_Name  \\\n",
       "0   \"Don't You Know Who I Am?\": How to Stay Sane i...   \n",
       "2                                           #Girlboss   \n",
       "4   #TheRealCinderella: #BestFriendsForever Series...   \n",
       "5                  10 Bedtime Stories For Little Kids   \n",
       "7                   10 Essential Pieces of Literature   \n",
       "9   10 Essential Success Mantras from the Bhagavad...   \n",
       "10                   10 Judgements That Changed India   \n",
       "11  10 Masterpieces You Have to Read Before You Die 1   \n",
       "12        10 Minutes 38 Seconds in This Strange World   \n",
       "13  10 Skills for Effective Business Communication...   \n",
       "\n",
       "                       Author  Rating  Number_of_Reviews  Price  \\\n",
       "0     Ramani S. Durvasula PhD     4.8                170  836.0   \n",
       "2              Sophia Amoruso     4.5               2272  615.0   \n",
       "4              Yesenia Vargas     4.3                179  586.0   \n",
       "5                        div.     4.5                  0  376.0   \n",
       "7               Khalil Gibran     4.5                  0   32.0   \n",
       "9                 Vimla Patil     4.2                 45  233.0   \n",
       "10                   Zia Mody     4.4                221  502.0   \n",
       "11                Jane Austen     4.4                344  401.0   \n",
       "12                Elif Shafak     4.5                520  752.0   \n",
       "13  Jessica Higgins JD MBA BB     4.6                 45  501.0   \n",
       "\n",
       "   Rating_Category  \n",
       "0        Excellent  \n",
       "2        Excellent  \n",
       "4        Very Good  \n",
       "5        Excellent  \n",
       "7        Excellent  \n",
       "9        Very Good  \n",
       "10       Very Good  \n",
       "11       Very Good  \n",
       "12       Excellent  \n",
       "13       Excellent  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display sample of cleaned data\n",
    "print(\" Sample of cleaned dataset:\")\n",
    "sample_cols = ['Book_Name', 'Author', 'Rating', 'Number_of_Reviews', 'Price', 'Rating_Category']\n",
    "df_final[sample_cols].head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audible_insight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
