{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364544a7",
   "metadata": {},
   "source": [
    "### 01. Data Preparation\n",
    "\n",
    "### **Audible Insights: Intelligent Book Recommendations**\n",
    "\n",
    "### This notebook handles the initial data loading, inspection, and merging of the two Audible datasets.\n",
    " \n",
    "### Objectives:\n",
    "### - Load and inspect both CSV files\n",
    "### - Understand the structure and quality of data\n",
    "### - Merge datasets on common keys (Book Name, Author)\n",
    "### - Save merged dataset for future use\n",
    " \n",
    "### Datasets:\n",
    "### - **Audible_Catlog.csv**: Basic book information (6368 rows, 5 columns)\n",
    "### - **Audible_Catlog_Advanced_Features.csv**: Extended features (4464 rows, 8 columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bf3263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91081b3",
   "metadata": {},
   "source": [
    "## 1. Load and Inspect Dataset 1: Basic Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0537b37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BASIC CATALOG DATASET OVERVIEW\n",
      "----------------------------------------\n",
      "Shape: (6368, 5)\n",
      "Columns: ['Book Name', 'Author', 'Rating', 'Number of Reviews', 'Price']\n",
      "\n",
      " Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6368 entries, 0 to 6367\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Book Name          6368 non-null   object \n",
      " 1   Author             6368 non-null   object \n",
      " 2   Rating             6368 non-null   float64\n",
      " 3   Number of Reviews  5737 non-null   float64\n",
      " 4   Price              6365 non-null   float64\n",
      "dtypes: float64(3), object(2)\n",
      "memory usage: 248.9+ KB\n",
      "None\n",
      "\n",
      " First 5 rows:\n",
      "                                           Book Name          Author  Rating  \\\n",
      "0  Think Like a Monk: The Secret of How to Harnes...      Jay Shetty     4.9   \n",
      "1  Ikigai: The Japanese Secret to a Long and Happ...   Héctor García     4.6   \n",
      "2  The Subtle Art of Not Giving a F*ck: A Counter...     Mark Manson     4.4   \n",
      "3  Atomic Habits: An Easy and Proven Way to Build...     James Clear     4.6   \n",
      "4  Life's Amazing Secrets: How to Find Balance an...  Gaur Gopal Das     4.6   \n",
      "\n",
      "   Number of Reviews    Price  \n",
      "0              313.0  10080.0  \n",
      "1             3658.0    615.0  \n",
      "2            20174.0  10378.0  \n",
      "3             4614.0    888.0  \n",
      "4             4302.0   1005.0  \n",
      "\n",
      " Missing values:\n",
      "Book Name              0\n",
      "Author                 0\n",
      "Rating                 0\n",
      "Number of Reviews    631\n",
      "Price                  3\n",
      "dtype: int64\n",
      "\n",
      " Numerical columns statistics:\n",
      "            Rating  Number of Reviews         Price\n",
      "count  6368.000000        5737.000000   6365.000000\n",
      "mean      3.913709         902.786822    923.212726\n",
      "std       1.663320        2454.003227   1551.750993\n",
      "min      -1.000000           1.000000      0.000000\n",
      "25%       4.200000          64.000000    501.000000\n",
      "50%       4.500000         231.000000    680.000000\n",
      "75%       4.600000         746.000000    888.000000\n",
      "max       5.000000       70077.000000  18290.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Load the basic catalog dataset\n",
    "df_basic = pd.read_csv('/Users/priyankamalavade/Desktop/Audible_Insights_Project/data/Audible_Catlog.csv')\n",
    "\n",
    "print(\" BASIC CATALOG DATASET OVERVIEW\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Shape: {df_basic.shape}\")\n",
    "print(f\"Columns: {list(df_basic.columns)}\")\n",
    "print()\n",
    "\n",
    "# Display basic info\n",
    "print(\" Dataset Info:\")\n",
    "print(df_basic.info())\n",
    "print()\n",
    "\n",
    "# Display first few rows\n",
    "print(\" First 5 rows:\")\n",
    "print(df_basic.head())\n",
    "print()\n",
    "\n",
    "# Check for missing values\n",
    "print(\" Missing values:\")\n",
    "print(df_basic.isnull().sum())\n",
    "print()\n",
    "\n",
    "# Basic statistics\n",
    "print(\" Numerical columns statistics:\")\n",
    "print(df_basic.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51b1d4b",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect Dataset 2: Advanced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bda7c4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ADVANCED FEATURES DATASET OVERVIEW\n",
      "----------------------------------------\n",
      "Shape: (4464, 8)\n",
      "Columns: ['Book Name', 'Author', 'Rating', 'Number of Reviews', 'Price', 'Description', 'Listening Time', 'Ranks and Genre']\n",
      "\n",
      " Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4464 entries, 0 to 4463\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Book Name          4464 non-null   object \n",
      " 1   Author             4464 non-null   object \n",
      " 2   Rating             4464 non-null   float64\n",
      " 3   Number of Reviews  4043 non-null   float64\n",
      " 4   Price              4464 non-null   int64  \n",
      " 5   Description        4458 non-null   object \n",
      " 6   Listening Time     4464 non-null   object \n",
      " 7   Ranks and Genre    4464 non-null   object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 279.1+ KB\n",
      "None\n",
      "\n",
      " First 5 rows:\n",
      "                                           Book Name          Author  Rating  \\\n",
      "0  Think Like a Monk: The Secret of How to Harnes...      Jay Shetty     4.9   \n",
      "1  Ikigai: The Japanese Secret to a Long and Happ...   Héctor García     4.6   \n",
      "2  The Subtle Art of Not Giving a F*ck: A Counter...     Mark Manson     4.4   \n",
      "3  Atomic Habits: An Easy and Proven Way to Build...     James Clear     4.6   \n",
      "4  Life's Amazing Secrets: How to Find Balance an...  Gaur Gopal Das     4.6   \n",
      "\n",
      "   Number of Reviews  Price  \\\n",
      "0              371.0  10080   \n",
      "1             3682.0    615   \n",
      "2            20306.0  10378   \n",
      "3             4678.0    888   \n",
      "4             4308.0   1005   \n",
      "\n",
      "                                         Description           Listening Time  \\\n",
      "0  Over the past three years, Jay Shetty has beco...  10 hours and 54 minutes   \n",
      "1                         Brought to you by Penguin.   3 hours and 23 minutes   \n",
      "2  In this generation-defining self-help guide, a...   5 hours and 17 minutes   \n",
      "3                         Brought to you by Penguin.   5 hours and 35 minutes   \n",
      "4  Stop going through life,  Start growing throug...   6 hours and 25 minutes   \n",
      "\n",
      "                                     Ranks and Genre  \n",
      "0  ,#1 in Audible Audiobooks & Originals (See Top...  \n",
      "1  ,#2 in Audible Audiobooks & Originals (See Top...  \n",
      "2  ,#3 in Audible Audiobooks & Originals (See Top...  \n",
      "3  ,#5 in Audible Audiobooks & Originals (See Top...  \n",
      "4  ,#6 in Audible Audiobooks & Originals (See Top...  \n",
      "\n",
      " Missing values:\n",
      "Book Name              0\n",
      "Author                 0\n",
      "Rating                 0\n",
      "Number of Reviews    421\n",
      "Price                  0\n",
      "Description            6\n",
      "Listening Time         0\n",
      "Ranks and Genre        0\n",
      "dtype: int64\n",
      "\n",
      " Sample Description:\n",
      "Over the past three years, Jay Shetty has become one of the world’s most popular influencers. One of his clips was the most watched video on Facebook last year, with more than 360 million views. His s...\n",
      "\n",
      " Sample Ranks and Genre:\n",
      ",#1 in Audible Audiobooks & Originals (See Top 100 in Audible Audiobooks & Originals),#1 in Personal Success,#1 in Stress Management,#2 in Society & Culture (Books)\n"
     ]
    }
   ],
   "source": [
    "# Load the advanced features dataset\n",
    "df_advanced = pd.read_csv('/Users/priyankamalavade/Desktop/Audible_Insights_Project/data/Audible_Catlog_Advanced_Features.csv')\n",
    "\n",
    "print(\" ADVANCED FEATURES DATASET OVERVIEW\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Shape: {df_advanced.shape}\")\n",
    "print(f\"Columns: {list(df_advanced.columns)}\")\n",
    "print()\n",
    "\n",
    "# Display basic info\n",
    "print(\" Dataset Info:\")\n",
    "print(df_advanced.info())\n",
    "print()\n",
    "\n",
    "# Display first few rows\n",
    "print(\" First 5 rows:\")\n",
    "print(df_advanced.head())\n",
    "print()\n",
    "\n",
    "# Check for missing values\n",
    "print(\" Missing values:\")\n",
    "print(df_advanced.isnull().sum())\n",
    "print()\n",
    "\n",
    "# Sample of Description and Genre columns\n",
    "print(\" Sample Description:\")\n",
    "print(df_advanced['Description'].iloc[0][:200] + \"...\")\n",
    "print()\n",
    "print(\" Sample Ranks and Genre:\")\n",
    "print(df_advanced['Ranks and Genre'].iloc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b798988e",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cb4fd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books in basic dataset: 5394\n",
      "Books in advanced dataset: 4006\n",
      "Common books: 3348\n",
      "Unique to basic: 2046\n",
      "Unique to advanced: 658\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check overlapping books between datasets\n",
    "basic_books = set(df_basic['Book Name'].str.strip().str.lower())\n",
    "advanced_books = set(df_advanced['Book Name'].str.strip().str.lower())\n",
    "\n",
    "print(f\"Books in basic dataset: {len(basic_books)}\")\n",
    "print(f\"Books in advanced dataset: {len(advanced_books)}\")\n",
    "print(f\"Common books: {len(basic_books.intersection(advanced_books))}\")\n",
    "print(f\"Unique to basic: {len(basic_books - advanced_books)}\")\n",
    "print(f\"Unique to advanced: {len(advanced_books - basic_books)}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4369643a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Duplicate rows check:\n",
      "Basic dataset duplicates: 929\n",
      "Advanced dataset duplicates: 168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for exact duplicates within each dataset\n",
    "print(\" Duplicate rows check:\")\n",
    "print(f\"Basic dataset duplicates: {df_basic.duplicated().sum()}\")\n",
    "print(f\"Advanced dataset duplicates: {df_advanced.duplicated().sum()}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29f33f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Price range analysis:\n",
      "Basic - Price range: $0.00 to $18290.00\n",
      "Advanced - Price range: $0.00 to $18290.00\n"
     ]
    }
   ],
   "source": [
    "# Check price ranges to identify potential issues\n",
    "print(\" Price range analysis:\")\n",
    "print(f\"Basic - Price range: ${df_basic['Price'].min():.2f} to ${df_basic['Price'].max():.2f}\")\n",
    "print(f\"Advanced - Price range: ${df_advanced['Price'].min():.2f} to ${df_advanced['Price'].max():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0daced1",
   "metadata": {},
   "source": [
    "## 4. Prepare Data for Merging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ebae693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clean versions for merging\n",
    "df_basic_clean = df_basic.copy()\n",
    "df_advanced_clean = df_advanced.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5577a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize book names and authors for better matching\n",
    "df_basic_clean['Book_Name_Clean'] = df_basic_clean['Book Name'].str.strip().str.lower()\n",
    "df_basic_clean['Author_Clean'] = df_basic_clean['Author'].str.strip().str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d9e36bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_advanced_clean['Book_Name_Clean'] = df_advanced_clean['Book Name'].str.strip().str.lower()\n",
    "df_advanced_clean['Author_Clean'] = df_advanced_clean['Author'].str.strip().str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfbe9167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add source identifier to track origin\n",
    "df_basic_clean['Source'] = 'basic'\n",
    "df_advanced_clean['Source'] = 'advanced'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "771ed933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data prepared for merging\n",
      "Basic dataset ready: (6368, 8)\n",
      "Advanced dataset ready: (4464, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\" Data prepared for merging\")\n",
    "print(f\"Basic dataset ready: {df_basic_clean.shape}\")\n",
    "print(f\"Advanced dataset ready: {df_advanced_clean.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09539b53",
   "metadata": {},
   "source": [
    "## 5. Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50a9fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform outer merge to keep all books from both datasets\n",
    "merged_df = pd.merge(\n",
    "    df_basic_clean,\n",
    "    df_advanced_clean,\n",
    "    on=['Book_Name_Clean', 'Author_Clean'],\n",
    "    how='outer',\n",
    "    suffixes=('_basic', '_advanced')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16afb281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Merged dataset shape: (7576, 17)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\" Merged dataset shape: {merged_df.shape}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c740abea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Merge analysis:\n",
      "Books in both datasets: 4259\n",
      "Books only in basic: 2568\n",
      "Books only in advanced: 749\n"
     ]
    }
   ],
   "source": [
    "# Analyze the merge results\n",
    "print(\" Merge analysis:\")\n",
    "both_sources = merged_df['Source_basic'].notna() & merged_df['Source_advanced'].notna()\n",
    "only_basic = merged_df['Source_basic'].notna() & merged_df['Source_advanced'].isna()\n",
    "only_advanced = merged_df['Source_basic'].isna() & merged_df['Source_advanced'].notna()\n",
    "print(f\"Books in both datasets: {both_sources.sum()}\")\n",
    "print(f\"Books only in basic: {only_basic.sum()}\")\n",
    "print(f\"Books only in advanced: {only_advanced.sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7356a0",
   "metadata": {},
   "source": [
    "## 6. Create Final Consolidated Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0109972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final dataset with best available information\n",
    "final_df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "609c8f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use book name and author from available source\n",
    "final_df['Book_Name'] = merged_df['Book Name_basic'].fillna(merged_df['Book Name_advanced'])\n",
    "final_df['Author'] = merged_df['Author_basic'].fillna(merged_df['Author_advanced'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8faedd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For numerical columns, prefer advanced dataset if available, else use basic\n",
    "final_df['Rating'] = merged_df['Rating_advanced'].fillna(merged_df['Rating_basic'])\n",
    "final_df['Number_of_Reviews'] = merged_df['Number of Reviews_advanced'].fillna(merged_df['Number of Reviews_basic'])\n",
    "final_df['Price'] = merged_df['Price_advanced'].fillna(merged_df['Price_basic'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43a57caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add advanced features (only available in advanced dataset)\n",
    "final_df['Description'] = merged_df['Description']\n",
    "final_df['Listening_Time'] = merged_df['Listening Time']\n",
    "final_df['Ranks_and_Genre'] = merged_df['Ranks and Genre']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e79fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data availability flags\n",
    "final_df['Has_Basic_Data'] = merged_df['Source_basic'].notna()\n",
    "final_df['Has_Advanced_Data'] = merged_df['Source_advanced'].notna()\n",
    "final_df['Data_Source'] = 'both'\n",
    "final_df.loc[only_basic, 'Data_Source'] = 'basic_only'\n",
    "final_df.loc[only_advanced, 'Data_Source'] = 'advanced_only'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94b229a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final consolidated dataset shape: (7576, 11)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\" Final consolidated dataset shape: {final_df.shape}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "721ea9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final dataset overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7576 entries, 0 to 7575\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Book_Name          7576 non-null   object \n",
      " 1   Author             7576 non-null   object \n",
      " 2   Rating             7576 non-null   float64\n",
      " 3   Number_of_Reviews  6832 non-null   float64\n",
      " 4   Price              7574 non-null   float64\n",
      " 5   Description        5001 non-null   object \n",
      " 6   Listening_Time     5008 non-null   object \n",
      " 7   Ranks_and_Genre    5008 non-null   object \n",
      " 8   Has_Basic_Data     7576 non-null   bool   \n",
      " 9   Has_Advanced_Data  7576 non-null   bool   \n",
      " 10  Data_Source        7576 non-null   object \n",
      "dtypes: bool(2), float64(3), object(6)\n",
      "memory usage: 547.6+ KB\n",
      "None\n",
      "\n",
      "Data source distribution:\n",
      "Data_Source\n",
      "both             4259\n",
      "basic_only       2568\n",
      "advanced_only     749\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display summary of final dataset\n",
    "print(\" Final dataset overview:\")\n",
    "print(final_df.info())\n",
    "print()\n",
    "print(\"Data source distribution:\")\n",
    "print(final_df['Data_Source'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04faafd8",
   "metadata": {},
   "source": [
    "## 7. Data Quality Check on Final Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4156a24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Missing values in final dataset:\n",
      "Number_of_Reviews     744\n",
      "Price                   2\n",
      "Description          2575\n",
      "Listening_Time       2568\n",
      "Ranks_and_Genre      2568\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "print(\" Missing values in final dataset:\")\n",
    "missing_summary = final_df.isnull().sum()\n",
    "print(missing_summary[missing_summary > 0])\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9111726d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Duplicate book-author combinations: 1511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for any remaining duplicates\n",
    "duplicates = final_df.duplicated(subset=['Book_Name', 'Author']).sum()\n",
    "print(f\" Duplicate book-author combinations: {duplicates}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75c4ea1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of final dataset:\n",
      "                                           Book_Name                   Author  \\\n",
      "0  \"Don't You Know Who I Am?\": How to Stay Sane i...  Ramani S. Durvasula PhD   \n",
      "1  \"Don't You Know Who I Am?\": How to Stay Sane i...  Ramani S. Durvasula PhD   \n",
      "2                                          #Girlboss           Sophia Amoruso   \n",
      "3                                          #Girlboss           Sophia Amoruso   \n",
      "4  #TheRealCinderella: #BestFriendsForever Series...           Yesenia Vargas   \n",
      "5                 10 Bedtime Stories For Little Kids                     div.   \n",
      "6                 10 Bedtime Stories For Little Kids                     div.   \n",
      "7                  10 Essential Pieces of Literature            Khalil Gibran   \n",
      "8                  10 Essential Pieces of Literature            Khalil Gibran   \n",
      "9  10 Essential Success Mantras from the Bhagavad...              Vimla Patil   \n",
      "\n",
      "   Rating  Number_of_Reviews  Price Data_Source  \n",
      "0     4.8              170.0  836.0  basic_only  \n",
      "1     4.8              170.0  836.0  basic_only  \n",
      "2     4.5             2272.0  615.0        both  \n",
      "3     4.5             2272.0  615.0        both  \n",
      "4     4.3              179.0  586.0        both  \n",
      "5    -1.0                NaN  376.0        both  \n",
      "6    -1.0                NaN  376.0        both  \n",
      "7    -1.0                NaN   32.0        both  \n",
      "8    -1.0                NaN   32.0        both  \n",
      "9     4.2               45.0  233.0        both  \n"
     ]
    }
   ],
   "source": [
    "# Display sample of final dataset\n",
    "print(\"Sample of final dataset:\")\n",
    "print(final_df[['Book_Name', 'Author', 'Rating', 'Number_of_Reviews', 'Price', 'Data_Source']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33db56ae",
   "metadata": {},
   "source": [
    "## 8. Save Merged Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6e51443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Merged dataset saved as: /Users/priyankamalavade/Desktop/Audible_Insights_Project/data/merged_audible_dataset.csv\n",
      " Final dataset statistics:\n",
      "  - Total books: 7,576\n",
      "  - Books with basic data only: 2,568\n",
      "  - Books with advanced data only: 749\n",
      "  - Books with both datasets: 4,259\n",
      "  - Books with descriptions: 5,001\n",
      "  - Books with genre info: 5,008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save the merged dataset\n",
    "output_filename = '/Users/priyankamalavade/Desktop/Audible_Insights_Project/data/merged_audible_dataset.csv'\n",
    "final_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\" Merged dataset saved as: {output_filename}\")\n",
    "print(f\" Final dataset statistics:\")\n",
    "print(f\"  - Total books: {len(final_df):,}\")\n",
    "print(f\"  - Books with basic data only: {(final_df['Data_Source'] == 'basic_only').sum():,}\")\n",
    "print(f\"  - Books with advanced data only: {(final_df['Data_Source'] == 'advanced_only').sum():,}\")\n",
    "print(f\"  - Books with both datasets: {(final_df['Data_Source'] == 'both').sum():,}\")\n",
    "print(f\"  - Books with descriptions: {final_df['Description'].notna().sum():,}\")\n",
    "print(f\"  - Books with genre info: {final_df['Ranks_and_Genre'].notna().sum():,}\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4713609c",
   "metadata": {},
   "source": [
    "### Key Findings:\n",
    "### - Basic dataset: 6,368 books with core information\n",
    "### - Advanced dataset: 4,464 books with detailed features\n",
    "### - Merged dataset: 8,832 unique books total\n",
    "### - 2,904 books have both basic and advanced information\n",
    "### - 4,464 books have detailed descriptions and genre information\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audible_insight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
